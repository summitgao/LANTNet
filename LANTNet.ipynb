{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-CoDattpbzs"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/summitgao/CAMixer/main/preclassify.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtZF8oxzqwbb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import skimage\n",
        "from skimage import io, measure\n",
        "import random\n",
        "import scipy.io as sio\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from preclassify import del2, srad, dicomp, FCM, hcluster\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "from collections import  Counter\n",
        "\n",
        "\n",
        "im1_path = 'Sulzberger2_1.bmp'\n",
        "im2_path = 'Sulzberger2_2.bmp'\n",
        "imgt_path = 'Sulzberger2_gt.bmp'\n",
        "\n",
        "\n",
        "# important parameter\n",
        "patch_size = 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3Z778ISqyzr"
      },
      "outputs": [],
      "source": [
        "def image_normalize(data):\n",
        "    import math\n",
        "    _mean = np.mean(data)\n",
        "    _std = np.std(data)\n",
        "    npixel = np.size(data) * 1.0\n",
        "    min_stddev = 1.0 / math.sqrt(npixel)\n",
        "    return (data - _mean) / max(_std, min_stddev)\n",
        "\n",
        "def image_padding(data,r):\n",
        "    if len(data.shape)==3:\n",
        "        data_new=np.lib.pad(data,((r,r),(r,r),(0,0)),'constant',constant_values=0)\n",
        "        return data_new\n",
        "    if len(data.shape)==2:\n",
        "        data_new=np.lib.pad(data,r,'constant',constant_values=0)\n",
        "        return data_new\n",
        "#生成自然数数组并打乱\n",
        "def arr(length):\n",
        "  arr=np.arange(length-1)\n",
        "  #print(arr)\n",
        "  random.shuffle(arr)\n",
        "  #print(arr)\n",
        "  return arr\n",
        "\n",
        "\n",
        "# 在每个像素周围提取 patch ，然后创建成符合 pytorch 处理的格式\n",
        "def createTrainingCubes(X, y, patch_size):\n",
        "    # 给 X 做 padding\n",
        "    margin = int((patch_size - 1) / 2)\n",
        "    zeroPaddedX = image_padding(X, margin)\n",
        "    # 把类别 uncertainty 的像素忽略\n",
        "    ele_num1 = np.sum(y==1)\n",
        "    ele_num2 = np.sum(y==2)\n",
        "    print(X.shape[2])\n",
        "    patchesData_1 = np.zeros( (ele_num1, patch_size, patch_size, X.shape[2]) )\n",
        "    patchesLabels_1 = np.zeros(ele_num1)\n",
        "\n",
        "    patchesData_2 = np.zeros((ele_num2, patch_size, patch_size, X.shape[2]))\n",
        "    patchesLabels_2 = np.zeros(ele_num2)\n",
        "\n",
        "    patchIndex_1 = 0\n",
        "    patchIndex_2 = 0\n",
        "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "            # remove uncertainty pixels\n",
        "            if y[r-margin, c-margin] == 1 :\n",
        "                patch_1 = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
        "                patchesData_1[patchIndex_1, :, :, :] = patch_1\n",
        "                patchesLabels_1[patchIndex_1] = y[r-margin, c-margin]\n",
        "                patchIndex_1 = patchIndex_1 + 1\n",
        "            elif y[r-margin, c-margin] == 2 :\n",
        "                patch_2 = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
        "                patchesData_2[patchIndex_2, :, :, :] = patch_2\n",
        "                patchesLabels_2[patchIndex_2] = y[r-margin, c-margin]\n",
        "                patchIndex_2 = patchIndex_2 + 1\n",
        "    patchesLabels_1 = patchesLabels_1-1\n",
        "    patchesLabels_2 = patchesLabels_2-1\n",
        "    \n",
        "    #调用arr函数打乱数组\n",
        "    arr_1=arr(len(patchesData_1))\n",
        "    arr_2=arr(len(patchesData_2))\n",
        "\n",
        "    train_len=8000  #设置训练集样本数\n",
        "    pdata=np.zeros((train_len, patch_size, patch_size, X.shape[2]))\n",
        "    plabels = np.zeros(train_len)\n",
        "    \n",
        "    for i in range(7000):\n",
        "      pdata[i,:,:,:]=patchesData_1[arr_1[i],:,:,:]\n",
        "      plabels[i]=patchesLabels_1[arr_1[i]]\n",
        "    for j in range(7000,train_len):\n",
        "      pdata[j,:,:,:]=patchesData_2[arr_2[j-7000],:,:,:]\n",
        "      plabels[j]=patchesLabels_2[arr_2[j-7000]]\n",
        "\n",
        "    return pdata, plabels\n",
        "\n",
        "\n",
        "def createTestingCubes(X, patch_size):\n",
        "    # 给 X 做 padding\n",
        "    margin = int((patch_size - 1) / 2)\n",
        "    zeroPaddedX = image_padding(X, margin)\n",
        "    patchesData = np.zeros( (X.shape[0]*X.shape[1], patch_size, patch_size, X.shape[2]) )\n",
        "    patchIndex = 0\n",
        "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
        "            patchesData[patchIndex, :, :, :] = patch\n",
        "            patchIndex = patchIndex + 1\n",
        "    return patchesData   \n",
        "\n",
        "\n",
        "#  Inputs:  gtImg  = ground truth image\n",
        "#           tstImg = change map\n",
        "#  Outputs: FA  = False alarms\n",
        "#           MA  = Missed alarms\n",
        "#           OE  = Overall error\n",
        "#           PCC = Overall accuracy\n",
        "def evaluate(gtImg, tstImg):\n",
        "    gtImg[np.where(gtImg>128)] = 255\n",
        "    gtImg[np.where(gtImg<128)] = 0\n",
        "    tstImg[np.where(tstImg>128)] = 255\n",
        "    tstImg[np.where(tstImg<128)] = 0\n",
        "    [ylen, xlen] = gtImg.shape\n",
        "    FA = 0\n",
        "    MA = 0\n",
        "    label_0 = np.sum(gtImg==0)\n",
        "    label_1 = np.sum(gtImg==255)\n",
        "    print(label_0)\n",
        "    print(label_1)\n",
        "\n",
        "    for j in range(0,ylen):\n",
        "        for i in range(0,xlen):\n",
        "            if gtImg[j,i]==0 and tstImg[j,i]!=0 :\n",
        "                FA = FA+1\n",
        "            if gtImg[j,i]!=0 and tstImg[j,i]==0 :\n",
        "                MA = MA+1\n",
        "  \n",
        "    OE = FA+MA\n",
        "    PCC = 1-OE/(ylen*xlen)\n",
        "    PRE=((label_1+FA-MA)*label_1+(label_0+MA-FA)*label_0)/((ylen*xlen)*(ylen*xlen))\n",
        "    KC=(PCC-PRE)/(1-PRE)\n",
        "    print(' Change detection results ==>')\n",
        "    print(' ... ... FP:  ', FA)\n",
        "    print(' ... ... FN:  ', MA)\n",
        "    print(' ... ... OE:  ', OE)\n",
        "    print(' ... ... PCC: ', format(PCC*100, '.2f'))\n",
        "    print(' ... ... KC: ', format(KC*100, '.2f'))\n",
        "\n",
        "\n",
        "def postprocess(res):\n",
        "    res_new = res\n",
        "    res = measure.label(res, connectivity=2)\n",
        "    num = res.max()\n",
        "    for i in range(1, num+1):\n",
        "        idy, idx = np.where(res==i)\n",
        "        if len(idy) <= 20:\n",
        "            res_new[idy, idx] = 0\n",
        "    return res_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH4uXB2uq1ck",
        "outputId": "314f53c2-3744-4e2a-c063-a84eab69a386"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256)\n",
            "... ... 1st round clustering ... ...\n",
            "... ... 2nd round clustering ... ...\n",
            "... ... hiearchical clustering finished !!!\n",
            "3\n",
            "... x train shape:  (8000, 3, 7, 7)\n",
            "... y train shape:  (8000,)\n",
            "... x test shape:  (65536, 3, 7, 7)\n"
          ]
        }
      ],
      "source": [
        "# read image, and then tranform to float32\n",
        "# 读取Sulzberger\n",
        "im1 = io.imread(im1_path)[:,:,0].astype(np.float32)\n",
        "im2 = io.imread(im2_path)[:,:,0].astype(np.float32)\n",
        "from PIL import Image\n",
        "im_gt = Image.open(imgt_path)\n",
        "im_gt = np.array(im_gt)\n",
        "np.unique(im_gt)\n",
        "print(im1.shape)\n",
        "\n",
        "im_di = dicomp(im1, im2)\n",
        "ylen, xlen = im_di.shape\n",
        "pix_vec = im_di.reshape([ylen*xlen, 1])\n",
        "\n",
        "\n",
        "# hiearchical FCM clustering\n",
        "# in the preclassification map, \n",
        "# pixels with high probability to be unchanged are labeled as 1\n",
        "# pixels with high probability to be changed are labeled as 2\n",
        "# pixels with uncertainty are labeled as 1.5\n",
        "preclassify_lab = hcluster(pix_vec, im_di) # 350*290\n",
        "print('... ... hiearchical clustering finished !!!')\n",
        "\n",
        "\n",
        "mdata = np.zeros([im1.shape[0], im1.shape[1], 3], dtype=np.float32)\n",
        "mdata[:,:,0] = im1\n",
        "mdata[:,:,1] = im2\n",
        "mdata[:,:,2] = im_di\n",
        "\n",
        "mlabel = preclassify_lab\n",
        "\n",
        "x_train, y_train = createTrainingCubes(mdata, mlabel, patch_size) #(10000,7,7,3)\n",
        "x_train = x_train.transpose(0, 3, 1, 2)\n",
        "print('... x train shape: ', x_train.shape)\n",
        "print('... y train shape: ', y_train.shape)\n",
        "\n",
        "\n",
        "x_test = createTestingCubes(mdata, patch_size)\n",
        "x_test = x_test.transpose(0, 3, 1, 2)\n",
        "print('... x test shape: ', x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaAVteSoq3tf"
      },
      "outputs": [],
      "source": [
        "\"\"\" Training dataset\"\"\"\n",
        "class TrainDS(torch.utils.data.Dataset): \n",
        "    def __init__(self):\n",
        "        self.len = x_train.shape[0]\n",
        "        self.x_data = torch.FloatTensor(x_train)\n",
        "        self.y_data = torch.LongTensor(y_train)        \n",
        "    def __getitem__(self, index):\n",
        "        # 根据索引返回数据和对应的标签\n",
        "        \n",
        "        #x=torch.FloatTensor(data_rotate(self.x_data[index].cpu().numpy()))\n",
        "        #y=torch.FloatTensor(gasuss_noise(self.y_data[index]))\n",
        "        #x=torch.FloatTensor(datarotate(self.x_data[index]))\n",
        "        #return x,self.y_data[index]\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "    def __len__(self): \n",
        "        # 返回文件数据的数目\n",
        "        return self.len\n",
        "\n",
        "# 创建 trainloader 和 testloader\n",
        "trainset = TrainDS()\n",
        "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=128, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ola-F4x4qVUF"
      },
      "outputs": [],
      "source": [
        "# 层注意力\n",
        "class LayerAttention(nn.Module):\n",
        "  def __init__(self, N):\n",
        "      super(LayerAttention, self).__init__()\n",
        "      self.N = N \n",
        "      self.weight = nn.Parameter(torch.eye(self.N,requires_grad=True))\n",
        "      self.softmax  = nn.Softmax(dim=-1)\n",
        "      \n",
        "  def forward(self,x):\n",
        "      # B x N x C x H x W\n",
        "      B, N, C, H, W = x.size()\n",
        "      group_mat = x.view(B, N, -1) # B*N*CHW 128*4*1568\n",
        "\n",
        "      # 只更新权重矩阵对角线上的元素\n",
        "      gradient_mask = torch.zeros(4, 4)\n",
        "      gradient_mask[0, 0] = 1.0\n",
        "      gradient_mask[1, 1] = 1.0\n",
        "      gradient_mask[2, 2] = 1.0\n",
        "      gradient_mask[3, 3] = 1.0\n",
        "      device = torch.device('cuda:0')\n",
        "      gradient_mask = gradient_mask.to(device) # 将tensor转移到cuda上,否则报错Expected all tensors to be on the same device（but cpu和cuda:0）\n",
        "      self.weight.register_hook(lambda grad: grad.mul_(gradient_mask))\n",
        "      \n",
        "      weight = self.weight.unsqueeze(0).repeat([B,1,1])\n",
        "      reweight = torch.bmm(weight, group_mat)\n",
        "      # 进行转置\n",
        "      reweight_trans = reweight.permute(0, 2, 1)\n",
        "\n",
        "      weight_tmp = torch.bmm(reweight,reweight_trans)\n",
        "      weight_tmp = torch.max(weight_tmp, -1, keepdim=True)[0].expand_as(weight_tmp)-weight_tmp # 让原矩阵的每一行最大值减去相应行的数\n",
        "      attention_weight = self.softmax(weight_tmp)\n",
        "\n",
        "      out = torch.bmm(attention_weight,reweight)\n",
        "      out = out.view(B, N, C, H, W)\n",
        "\n",
        "      out = out + x\n",
        "      out = out.view(B, -1, H, W)\n",
        "\n",
        "      return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riex-GDcLVLZ"
      },
      "outputs": [],
      "source": [
        "# 噪声鲁棒的损失函数\n",
        "class Loss(torch.nn.Module):\n",
        "  def __init__(self, alpha=0.1, beta=0.9, classes=2):\n",
        "      super(Loss, self).__init__()\n",
        "      self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "      self.alpha = alpha\n",
        "      self.beta = beta\n",
        "      self.classes = classes\n",
        "      self.ce = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  def forward(self, pred, labels):\n",
        "      # CE\n",
        "      ce = self.ce(pred, labels)\n",
        "      # MAE\n",
        "      pred = F.softmax(pred, dim=1)\n",
        "      label_one_hot = torch.nn.functional.one_hot(labels, self.classes).float().to(self.device)\n",
        "      mae = 2 - 2 * (torch.sum(pred * label_one_hot, dim=1)) # 点乘的作用就是取pred的对应类别的那个预测概率\n",
        "      # Loss\n",
        "      loss = self.alpha * ce + self.beta * mae.mean()\n",
        "      return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUSdiicG3-8Y"
      },
      "outputs": [],
      "source": [
        "class LANTNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LANTNet, self).__init__() \n",
        "        \n",
        "        inchannel = 3\n",
        "        self.conv1 = nn.Conv2d(inchannel, 8, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "        self.conv1_1 = nn.Conv2d(8, 32, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn1_1 = nn.BatchNorm2d(32)\n",
        "\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.bn2_1 = nn.BatchNorm2d(16)\n",
        "        self.conv2_11 = nn.Conv2d(16, 32, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn2_11 = nn.BatchNorm2d(32)\n",
        "\n",
        "\n",
        "        self.conv2_2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.bn2_2 = nn.BatchNorm2d(32)\n",
        "        self.conv2_22 = nn.Conv2d(32, 32, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn2_22 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv2_3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.bn2_3 = nn.BatchNorm2d(32)\n",
        "        self.conv2_33 = nn.Conv2d(32, 32, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn2_33 = nn.BatchNorm2d(32)\n",
        "\n",
        "\n",
        "        self.lam= LayerAttention(4)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(128, 4, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.bn3 = nn.BatchNorm2d(4)\n",
        "\n",
        "        self.linear1=nn.Linear(196, 10) \n",
        "        self.linear2=nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        ori_out1 = F.relu(self.bn1(self.conv1(x)))\n",
        "        m1 = F.relu(self.bn1_1(self.conv1_1(ori_out1)))# 统一到32个通道上来\n",
        "\n",
        "        ori_out2 = F.relu(self.bn2_1(self.conv2_1(ori_out1)))\n",
        "        m2 = F.relu(self.bn2_11(self.conv2_11(ori_out2)))# 统一到32个通道上来\n",
        "\n",
        "        ori_out3 = F.relu(self.bn2_2(self.conv2_2(ori_out2)))\n",
        "        m3 = F.relu(self.bn2_22(self.conv2_22(ori_out3)))# 统一到32个通道上来\n",
        "\n",
        "        ori_out4 = F.relu(self.bn2_3(self.conv2_3(ori_out3)))\n",
        "        m4 = F.relu(self.bn2_33(self.conv2_33(ori_out4)))# 统一到32个通道上来\n",
        "\n",
        "        out5 = torch.stack([m1, m2, m3, m4],dim = 1)\n",
        "        out5=self.lam(out5)\n",
        "        out = F.relu(self.bn3(self.conv3(out5)))\n",
        "        out = out.view(out.size(0), -1)\n",
        "        #print(out.shape)\n",
        "        out_1 = self.linear1(out)\n",
        "        out = self.linear2(out_1)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vibf2AkprDIF",
        "outputId": "fc2e32b9-1bf3-421e-a878-17b0e2e0cd47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 1]  [loss avg: 10.6556]  [current loss: 0.0136]\n",
            "[Epoch: 2]  [loss avg: 5.9442]  [current loss: 0.0072]\n",
            "[Epoch: 3]  [loss avg: 4.2065]  [current loss: 0.0037]\n",
            "[Epoch: 4]  [loss avg: 3.3369]  [current loss: 0.0011]\n",
            "[Epoch: 5]  [loss avg: 2.7831]  [current loss: 0.0019]\n",
            "[Epoch: 6]  [loss avg: 2.4313]  [current loss: 0.1196]\n",
            "[Epoch: 7]  [loss avg: 2.1135]  [current loss: 0.0001]\n",
            "[Epoch: 8]  [loss avg: 1.8628]  [current loss: 0.0000]\n",
            "[Epoch: 9]  [loss avg: 1.6826]  [current loss: 0.0002]\n",
            "[Epoch: 10]  [loss avg: 1.5552]  [current loss: 0.0015]\n",
            "[Epoch: 11]  [loss avg: 1.4652]  [current loss: 0.0001]\n",
            "[Epoch: 12]  [loss avg: 1.3754]  [current loss: 0.0005]\n",
            "[Epoch: 13]  [loss avg: 1.2744]  [current loss: 0.0003]\n",
            "[Epoch: 14]  [loss avg: 1.1987]  [current loss: 0.0000]\n",
            "[Epoch: 15]  [loss avg: 1.1267]  [current loss: 0.0001]\n",
            "[Epoch: 16]  [loss avg: 1.0637]  [current loss: 0.0000]\n",
            "[Epoch: 17]  [loss avg: 1.0071]  [current loss: 0.0259]\n",
            "[Epoch: 18]  [loss avg: 0.9652]  [current loss: 0.0000]\n",
            "[Epoch: 19]  [loss avg: 0.9206]  [current loss: 0.0009]\n",
            "[Epoch: 20]  [loss avg: 0.8781]  [current loss: 0.0000]\n",
            "[Epoch: 21]  [loss avg: 0.8444]  [current loss: 0.0548]\n",
            "[Epoch: 22]  [loss avg: 0.8104]  [current loss: 0.0188]\n",
            "[Epoch: 23]  [loss avg: 0.7857]  [current loss: 0.0000]\n",
            "[Epoch: 24]  [loss avg: 0.7584]  [current loss: 0.0000]\n",
            "[Epoch: 25]  [loss avg: 0.7306]  [current loss: 0.0000]\n",
            "[Epoch: 26]  [loss avg: 0.7049]  [current loss: 0.0000]\n",
            "[Epoch: 27]  [loss avg: 0.6897]  [current loss: 0.0000]\n",
            "[Epoch: 28]  [loss avg: 0.6694]  [current loss: 0.0460]\n",
            "[Epoch: 29]  [loss avg: 0.6507]  [current loss: 0.0001]\n",
            "[Epoch: 30]  [loss avg: 0.6367]  [current loss: 0.0000]\n",
            "[Epoch: 31]  [loss avg: 0.6181]  [current loss: 0.0000]\n",
            "[Epoch: 32]  [loss avg: 0.5993]  [current loss: 0.0002]\n",
            "[Epoch: 33]  [loss avg: 0.5836]  [current loss: 0.0189]\n",
            "[Epoch: 34]  [loss avg: 0.5731]  [current loss: 0.0001]\n",
            "[Epoch: 35]  [loss avg: 0.5608]  [current loss: 0.0000]\n",
            "[Epoch: 36]  [loss avg: 0.5468]  [current loss: 0.0000]\n",
            "[Epoch: 37]  [loss avg: 0.5326]  [current loss: 0.0000]\n",
            "[Epoch: 38]  [loss avg: 0.5210]  [current loss: 0.0000]\n",
            "[Epoch: 39]  [loss avg: 0.5091]  [current loss: 0.0000]\n",
            "[Epoch: 40]  [loss avg: 0.4988]  [current loss: 0.0000]\n",
            "[Epoch: 41]  [loss avg: 0.4888]  [current loss: 0.0098]\n",
            "[Epoch: 42]  [loss avg: 0.4785]  [current loss: 0.0003]\n",
            "[Epoch: 43]  [loss avg: 0.4678]  [current loss: 0.0000]\n",
            "[Epoch: 44]  [loss avg: 0.4582]  [current loss: 0.0011]\n",
            "[Epoch: 45]  [loss avg: 0.4487]  [current loss: 0.0000]\n",
            "[Epoch: 46]  [loss avg: 0.4406]  [current loss: 0.0000]\n",
            "[Epoch: 47]  [loss avg: 0.4350]  [current loss: 0.0078]\n",
            "[Epoch: 48]  [loss avg: 0.4342]  [current loss: 0.2481]\n",
            "[Epoch: 49]  [loss avg: 0.4278]  [current loss: 0.0000]\n",
            "[Epoch: 50]  [loss avg: 0.4219]  [current loss: 0.0000]\n",
            "[Epoch: 51]  [loss avg: 0.4148]  [current loss: 0.0000]\n",
            "[Epoch: 52]  [loss avg: 0.4080]  [current loss: 0.0000]\n",
            "[Epoch: 53]  [loss avg: 0.4013]  [current loss: 0.0000]\n",
            "[Epoch: 54]  [loss avg: 0.3939]  [current loss: 0.0000]\n",
            "[Epoch: 55]  [loss avg: 0.3869]  [current loss: 0.0000]\n",
            "[Epoch: 56]  [loss avg: 0.3816]  [current loss: 0.0003]\n",
            "[Epoch: 57]  [loss avg: 0.3755]  [current loss: 0.0000]\n",
            "[Epoch: 58]  [loss avg: 0.3704]  [current loss: 0.0000]\n",
            "[Epoch: 59]  [loss avg: 0.3650]  [current loss: 0.0000]\n",
            "[Epoch: 60]  [loss avg: 0.3592]  [current loss: 0.0001]\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# 使用GPU训练，可以在菜单 \"代码执行工具\" -> \"更改运行时类型\" 里进行设置\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "istrain = True\n",
        "# 网络放到GPU上\n",
        "net =LANTNet().to(device)\n",
        "criterion = Loss(alpha=0.1, beta=0.9, classes=2).to(device)\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "net.train()\n",
        "\n",
        "# 开始训练\n",
        "total_loss = 0\n",
        "for epoch in range(60):\n",
        "    \n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 优化器梯度归零\n",
        "        optimizer.zero_grad()\n",
        "        # 正向传播 +　反向传播 + 优化 \n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print('[Epoch: %d]  [loss avg: %.4f]  [current loss: %.4f]' %(epoch + 1, total_loss/(epoch+1), loss.item()))\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xziOVuKPsWcN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "5082ced0-7ece-464e-8aee-3720caa8c52c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "... ... row 50  handling ... ...\n",
            "... ... row 100  handling ... ...\n",
            "... ... row 150  handling ... ...\n",
            "... ... row 200  handling ... ...\n",
            "... ... row 250  handling ... ...\n",
            "49184\n",
            "16352\n",
            " Change detection results ==>\n",
            " ... ... FP:   990\n",
            " ... ... FN:   921\n",
            " ... ... OE:   1911\n",
            " ... ... PCC:  97.08\n",
            " ... ... KC:  92.22\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f89b4e56450>"
            ]
          },
          "metadata": {},
          "execution_count": 327
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# 逐像素预测类别\n",
        "istrain=False\n",
        "net.eval()\n",
        "outputs = np.zeros((ylen, xlen))\n",
        "glo_fin=torch.Tensor([]).cuda()\n",
        "dct_fin=torch.Tensor([]).cuda()\n",
        "for i in range(ylen):\n",
        "    for j in range(xlen):\n",
        "        img_patch = x_test[i*xlen+j, :, :, :]\n",
        "        img_patch = img_patch.reshape(1, img_patch.shape[0], img_patch.shape[1], img_patch.shape[2])\n",
        "        img_patch = torch.FloatTensor(img_patch).to(device)\n",
        "        prediction = net(img_patch)\n",
        "\n",
        "        prediction = np.argmax(prediction.detach().cpu().numpy(), axis=1)\n",
        "        outputs[i, j] = prediction + 1\n",
        "\n",
        "            \n",
        "    if (i+1) % 50 == 0:\n",
        "        print('... ... row', i+1, ' handling ... ...')\n",
        "\n",
        "outputs = outputs-1\n",
        "\n",
        "plt.imshow(outputs, 'gray')\n",
        "res = outputs*255\n",
        "res = postprocess(res)\n",
        "evaluate(im_gt, res)\n",
        "plt.imshow(res, 'gray')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "mount_file_id": "1-bdVcRH866JbQ90LVF-U5HoX3z6ROMVZ",
      "authorship_tag": "ABX9TyPquBxPWKotU/qi9UdO9NCC"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
